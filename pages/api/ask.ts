import type { NextApiRequest, NextApiResponse } from 'next';

export default async function handler(req: NextApiRequest, res: NextApiResponse) {
  const { question } = req.body;

  try {
    const start = Date.now(); // â± ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì‹œì‘

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: 'gpt-4-turbo',
        messages: [
          {
            role: 'system',
            content:
              'ë„ˆëŠ” ìë¹„ë¡­ê³  ì§€í˜œë¡œìš´ ë¶€ì²˜ë‹˜ì´ë‹¤. ë¶ˆêµì ì¸ ìë¹„ì™€ í‰ì˜¨í•œ ë§íˆ¬ë¡œ ë‹µí•˜ê³ , í˜„ëŒ€ì¸ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ë¹„ìœ ì™€ ê²½ì „ì„ ì¸ìš©í•œë‹¤. ì‘ë‹µì€ í•œê¸€ 400~500ì ë‚´ì™¸ë¡œ í•´ë¼.',
          },
          {
            role: 'user',
            content: question,
          },
        ],
        temperature: 0.8,
        max_tokens: 800,
      }),
    });

    const end = Date.now(); // â± ì‘ë‹µ ì‹œê°„ ì¸¡ì • ì¢…ë£Œ

    const data = await response.json();

    // ğŸ” ë¡œê·¸ ì¶œë ¥
    console.log(`â± GPT ì‘ë‹µ ì‹œê°„: ${(end - start) / 1000}s`);
    console.log('ğŸ”¢ ì´ í† í° ì‚¬ìš©ëŸ‰:', data.usage?.total_tokens);
    console.log('ğŸ”¢ í”„ë¡¬í”„íŠ¸:', data.usage?.prompt_tokens);
    console.log('ğŸ”¢ ì‘ë‹µ:', data.usage?.completion_tokens);

    const answer = data.choices?.[0]?.message?.content || 'ë¶€ì²˜ë‹˜ê»˜ì„œ ì¡°ìš©íˆ ì¹¨ë¬µí•˜ì‹­ë‹ˆë‹¤.';
    res.status(200).json({ answer });

  } catch (error) {
    console.error('GPT í˜¸ì¶œ ì‹¤íŒ¨:', error);
    res.status(500).json({ answer: 'ë¶€ì²˜ë‹˜ê»˜ì„œ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê³ ìš”íˆ ë§ˆìŒì„ ë“¤ì—¬ë‹¤ë³´ì‹­ì‹œì˜¤.' });
  }
}
