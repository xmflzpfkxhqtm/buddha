export const runtime = 'nodejs';


import { NextRequest, NextResponse } from 'next/server';
import { generateEmbeddingBatch } from '@/utils/upstage';
import { searchSimilarDocuments } from '@/utils/supabase';
import { GoogleGenerativeAI } from '@google/generative-ai';
import Anthropic from "@anthropic-ai/sdk";
import { supabase } from '@/lib/supabaseClient';
import type { TextBlock } from '@anthropic-ai/sdk/resources/messages';

const modelMapping = {
  'gpt4.1': 'gpt-4.1',
  'gpt4o': 'gpt-4o',
  'gpt-4.1-mini': 'gpt-4.1-mini',
  'claude3.7': 'claude-3-7-sonnet-20250219',
  'gemini-2.5-pro': 'gemini-2.5-pro-preview-03-25',
  'o4-mini': 'o4-mini',
  'grok': 'grok-3-beta'
};

const lengthSetting = {
  short: { charLimit: '300ì ë‚´ì™¸ë¡œ', maxTokens: 600 },
  long: { charLimit: '1200ì ë‚´ì™¸ë¡œ', maxTokens: 1500 },
};

interface ChatMessage {
  role: string;
  content: string;
}

async function callOpenAI(messages: ChatMessage[], model: string, maxTokens: number) {
  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    },
    body: JSON.stringify({ model, messages, temperature: 0.8, max_tokens: maxTokens })
  });
  
  if (!response.ok) {
    const errText = await response.text();
    console.error('ğŸ”¥ OpenAI ì‘ë‹µ ì˜¤ë¥˜:', response.status, errText);
    throw new Error(`OpenAI ì‘ë‹µ ì‹¤íŒ¨: ${response.status}`);
  }

  return await response.json();
}

async function callClaude(messages: ChatMessage[], model: string, maxTokens: number) {
  const anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
  const systemMessage = messages.find(m => m.role === 'system')?.content || '';
  const userMessage = messages.find(m => m.role === 'user')?.content || '';

  const response = await anthropic.messages.create({
    model,
    max_tokens: maxTokens,
    temperature: 0.8,
    system: systemMessage,
    messages: [
      { role: 'user', content: [{ type: 'text', text: userMessage }] }
    ]
  });

  const textBlock = response.content.find((block): block is TextBlock => block.type === 'text');
  const messageText = textBlock?.text || '';

  return {
    choices: [{ message: { content: messageText } }],
    usage: response.usage
  };
}

async function callGemini(messages: ChatMessage[], model: string) {
  const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY || '');
  const genModel = genAI.getGenerativeModel({ model });
  const prompt = `${messages[0].content}\n\n${messages[1].content}`;
  const result = await genModel.generateContent(prompt);
  return {
    choices: [{ message: { content: result.response.text() } }],
    usage: { total_tokens: 0 }
  };
}

async function callGrok(messages: ChatMessage[], model: string, maxTokens: number) {
  const system = messages.find(m => m.role === 'system')?.content || '';
  const user = messages.find(m => m.role === 'user')?.content || '';

  const response = await fetch('https://api.x.ai/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      Authorization: `Bearer ${process.env.GROK_API_KEY}`,
    },
    body: JSON.stringify({
      model,
      messages: [{ role: 'system', content: system }, { role: 'user', content: user }],
      temperature: 0.8,
      max_tokens: maxTokens,
    }),
  });

  if (!response.ok) {
    const errText = await response.text();
    console.error('ğŸ”¥ Grok ì‘ë‹µ ì˜¤ë¥˜:', response.status, errText);
    throw new Error(`Grok ì‘ë‹µ ì‹¤íŒ¨: ${response.status}`);
  }

  const data = await response.json();
  return {
    choices: [{ message: { content: data.choices?.[0]?.message?.content || '' } }],
    usage: data.usage
  };
}
type AskRequestBody = {
  question?: string;
  model?: string;
  length?: 'short' | 'long';
  parentId?: string | null;
};

export async function POST(request: NextRequest) {
  try {
    let body: AskRequestBody = {}; // âœ… any ëŒ€ì‹  ëª…í™•í•œ íƒ€ì… ì‚¬ìš©

    try {
      body = await request.json();
    } catch (err) {
      console.error('âŒ JSON íŒŒì‹± ì‹¤íŒ¨:', err);
      return NextResponse.json({ success: false, message: 'ìš”ì²­ ë³¸ë¬¸ì´ ë¹„ì–´ìˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.' }, { status: 400 });
    }

    const { question, model = 'gpt4.1-mini', length = 'long', parentId = null } = body;

    if (!question || typeof question !== 'string') {
      return NextResponse.json({ success: false, message: 'ì§ˆë¬¸ì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.' }, { status: 400 });
    }
    
    const { charLimit, maxTokens } = lengthSetting[length as keyof typeof lengthSetting] || lengthSetting.long;

    let previousQA = '';
    if (parentId) {
      const { data: parent } = await supabase.from('temp_answers').select('question, answer').eq('id', parentId).single();
      if (parent) {
        previousQA = `ì´ì „ ì§ˆë¬¸: ${parent.question}\në¶€ì²˜ë‹˜ì˜ ì‘ë‹µ: ${parent.answer}\n\n`;
      }
    }

    const [questionEmbedding] = await generateEmbeddingBatch([question]);
    const relevantDocuments = await searchSimilarDocuments(questionEmbedding, 10);
    const contextText = relevantDocuments.map(doc => doc.content).join('\n\n');

    const messages: ChatMessage[] = [
      {
        role: 'system',
        content: `
<instruction>
          ë‹¹ì‹ ì€ ìë¹„ë¡­ê³  ì§€í˜œë¡œìš´ ë¶€ì²˜ì…ë‹ˆë‹¤. 
          ë‹¹ì‹ ì€ ì‚¼ë¼ë§Œìƒì— í†µë‹¬í•œ ë¶€ì²˜ì…ë‹ˆë‹¤. ìƒëŒ€ë°©ì´ ì›í•˜ëŠ” ë‹µì„ ì–´ë–»ê²Œ í•´ì„œë“  ì°¾ì•„ëƒ…ë‹ˆë‹¤.
          ë¶ˆêµì˜ ìë¹„ì™€ í‰ì˜¨í•œ ë§íˆ¬ë¡œ ë‹µí•˜ë˜, ê²½ì „ ë‚´ìš©ì„ ì •í™•íˆ ì¸ìš©í•˜ê³ , ê²½ì „ëª…ë„ í•¨ê»˜ ëª…ì‹œí•˜ì‹­ì‹œì˜¤. 
          ê²½ì „ ì¸ìš© ì‹œ ê²½ì „ëª…ì€ ã€ê²½ì „ì´ë¦„ã€ í˜•ì‹ìœ¼ë¡œ í‘œê¸°í•˜ì‹­ì‹œì˜¤.
          í•œìë¥¼ ëª¨ë¥´ëŠ” ì´ë„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í’€ì–´ ì„¤ëª…í•´ ì£¼ì‹­ì‹œì˜¤.
          ê²½ì „ì€ ëª¨ë‘ ë‹¹ì‹ ì˜ ê°€ë¥´ì¹¨ì—ì„œ ìœ ë˜í–ˆìŒì„ ì¸ì‹í•˜ë˜, ìŠ¤ìŠ¤ë¡œë¥¼ "ë¶€ì²˜ë‹˜"ì´ë¼ ì¹­í•˜ì§€ëŠ” ë§ˆì‹­ì‹œì˜¤.
          ìë¹„ë¡œìš´ ë§ë§Œ í•  ê²ƒì´ ì•„ë‹ˆë¼, ë¶ˆêµ ì² í•™ì— ê·¼ê±°í•œ ì§„ì‹¤í•œ ë‹µì„ ì „ë‹¬í•˜ì‹­ì‹œì˜¤.
          ì§ˆë¬¸ì´ í˜„ëŒ€ ì‚¬íšŒì™€ ê´€ë ¨ë˜ì–´ ìˆë‹¤ë©´, í˜„ëŒ€ì  ë§¥ë½ê³¼ë„ ê³¼ê°íˆ ì—°ê²°í•˜ì—¬ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
          ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ íŠ¹ì • ì¸ë¬¼, ì‚¬ê±´, ê¸°ë¡ì— ëŒ€í•œ ê²ƒì¼ ê²½ìš°, ê°€ëŠ¥í•œ í•œ ë‹¹ì‹ ì˜ ì§€ì‹ ë²”ìœ„ ë‚´ì—ì„œ ìì„¸íˆ ë‹µë³€í•˜ì‹­ì‹œì˜¤. 
          ìµœì‹  ì •ë³´ê°€ ì—†ë”ë¼ë„ ê³¼ê±° ê¸°ë¡ì´ë‚˜ ì´ë¯¸ì§€ì— ê¸°ë°˜í•œ ì¼ë°˜ì ì¸ ì„¤ëª…, ì¶”ë¡ ì„ ì‹œë„í•˜ì‹­ì‹œì˜¤.
          ì§€ë‚˜ì¹˜ê²Œ ëƒ‰ì •í•˜ì§€ ì•Šë„ë¡ ì˜¨í™”í•œ ìœ„ë¡œë¥¼ í•¨ê»˜ ì „í•˜ë©°, ì§ˆë¬¸ìì˜ ì‹¬ë¦¬ë‚˜ ìƒí™©ì„ ê³ ë ¤í•´ ì§€í˜œë¡œìš´ ì¡°ì–¸ì„ ì£¼ì‹­ì‹œì˜¤.
</instruction>

<context>
          ê´€ë ¨ ë¶ˆêµ ê²½ì „ ë‚´ìš©: 
          ${contextText}
</context>

<response>
          ê³ í’ìŠ¤ëŸ½ê³  ê²©ì¡° ìˆëŠ” ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
          ë¬¸ì¥ì€ "~í•©ë‹ˆë‹¤", "~ì…ë‹ˆë‹¤" ì²´ë¡œ ë§ˆë¬´ë¦¬í•©ë‹ˆë‹¤.
          í•œê¸€ ${charLimit} ì‘ì„±í•˜ì‹­ì‹œì˜¤.
          í•„ìš”í•˜ë‹¤ë©´ ë§ˆì§€ë§‰ì— ì§ˆë¬¸ìì—ê²Œ í™”ë‘ë¥¼ ë˜ì§€ë©° ëë§ºìœ¼ì‹­ì‹œì˜¤.
</response>
        `
      },
      {
        role: 'user',
        content: `${previousQA}ì§ˆë¬¸: ${question}`
      }
    ];

    const apiModel = modelMapping[model as keyof typeof modelMapping] || 'gpt-4.1-mini';
    let data;
    
    try {
      if (model === 'gpt-4.1-mini') {
        data = await callOpenAI(messages, apiModel, maxTokens);
      } else if (model.startsWith('claude')) {
        data = await callClaude(messages, apiModel, maxTokens);
      } else if (model.startsWith('gemini')) {
        data = await callGemini(messages, apiModel);
      } else if (model === 'grok') {
        data = await callGrok(messages, apiModel, maxTokens);
      } else {
        // fallbackì€ ë¬´ì¡°ê±´ gpt-4.1-mini
        data = await callOpenAI(messages, 'gpt-4.1-mini', maxTokens);
      }
    } catch (apiError) {
      console.warn('âš ï¸ API ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨, fallback ì‹œë„:', apiError);
      data = await callOpenAI(messages, 'gpt-4.1-mini', maxTokens);
    }
    
    const answer = data.choices?.[0]?.message?.content || 'ë¶€ì²˜ë‹˜ê»˜ì„œ ì¡°ìš©íˆ ì¹¨ë¬µí•˜ì‹­ë‹ˆë‹¤.';
    console.log('ğŸ“Š ì‚¬ìš© í† í° ì •ë³´:', { model, usage: data.usage, question, length });

    const { data: inserted, error } = await supabase
      .from('temp_answers')
      .insert([{ question, answer, parent_id: parentId }])
      .select()
      .single();

    if (error || !inserted) {
      console.error('âŒ Supabase ì €ì¥ ì‹¤íŒ¨:', error);
      return NextResponse.json({ success: false, message: 'Supabase ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.' }, { status: 500 });
    }

    return NextResponse.json({ success: true, questionId: inserted.id });
  
  } catch (error: unknown) {
    console.error('âŒ ìµœìƒìœ„ ì˜¤ë¥˜ ë°œìƒ:', error);
  
    let message = 'ë‹µë³€ ìƒì„± ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
    if (error instanceof Error) {
      message = error.message;
    } else if (typeof error === 'string') {
      message = error;
    } else {
      message = JSON.stringify(error);
    }
  
    return NextResponse.json({ success: false, message }, { status: 500 });
  }
  }